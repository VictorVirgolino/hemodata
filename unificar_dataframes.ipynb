{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad37b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a leitura dos arquivos XLSX...\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_al.xlsx. Estado atribuído: Alagoas\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_am.xlsx. Estado atribuído: Amazonas\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_ap.xlsx. Estado atribuído: Amapá\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_ba.xlsx. Estado atribuído: Bahia\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_ce.xlsx. Estado atribuído: Ceará\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_df.xlsx. Estado atribuído: Distrito Federal\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_es.xlsx. Estado atribuído: Espírito Santo\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_go.xlsx. Estado atribuído: Goiás\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_hm.xlsx. Estado atribuído: Hemominas\n",
      "Arquivo lido com sucesso: dados_processados\\hemoprod_ma.xlsx. Estado atribuído: Maranhão\n",
      "\n",
      "Todos os arquivos foram concatenados em um único DataFrame.\n",
      "Shape do DataFrame final: (4486, 271)\n",
      "\n",
      "--- Head da Coluna 'estado' para verificação ---\n",
      "0    Alagoas\n",
      "1    Alagoas\n",
      "2    Alagoas\n",
      "3    Alagoas\n",
      "4    Alagoas\n",
      "5    Alagoas\n",
      "6    Alagoas\n",
      "7    Alagoas\n",
      "8    Alagoas\n",
      "9    Alagoas\n",
      "Name: estado, dtype: object\n",
      "-------------------------------------------------\n",
      "Tentando converter a coluna 'data_inicio' para o tipo datetime...\n",
      "Conversão de 'data_inicio' concluída. Novo tipo: datetime64[ns]\n",
      "Tentando converter a coluna 'data_ultima_acao' para o tipo datetime...\n",
      "Conversão de 'data_ultima_acao' concluída. Novo tipo: datetime64[ns]\n",
      "Tentando converter a coluna 'ip' para o tipo string...\n",
      "Conversão de 'ip' concluída. Novo tipo: object\n",
      "Tentando converter a coluna 'cnpj' para o tipo string...\n",
      "Conversão de 'cnpj' concluída. Novo tipo: object\n",
      "Tentando converter a coluna 'cnes' para o tipo string...\n",
      "Conversão de 'cnes' concluída. Novo tipo: object\n",
      "Tentando converter a coluna 'hemoprod_1_observacoes' para o tipo string...\n",
      "Conversão de 'hemoprod_1_observacoes' concluída. Novo tipo: object\n",
      "Tentando converter a coluna 'hemoprod_3_observacoes' para o tipo string...\n",
      "Conversão de 'hemoprod_3_observacoes' concluída. Novo tipo: object\n",
      "Tentando converter a coluna 'estado' para o tipo string...\n",
      "Conversão de 'estado' concluída. Novo tipo: object\n",
      "\n",
      "DataFrame salvo com sucesso como 'dados_processados/hemoprod_nacional.parquet'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_28980\\2766181610.py:101: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_final = pd.concat(lista_dfs, axis=0, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# LÓGICA DE EXTRAÇÃO DE ESTADO (COPIADA DO 'estado_extractor.py')\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def obter_mapeamento_estados():\n",
    "    \"\"\"\n",
    "    Retorna o dicionário de mapeamento dos códigos de duas letras \n",
    "    (presentes no nome do arquivo) para os nomes completos dos estados/entidades.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'al': 'Alagoas',\n",
    "        'am': 'Amazonas',\n",
    "        'ap': 'Amapá',\n",
    "        'ba': 'Bahia',\n",
    "        'ce': 'Ceará',\n",
    "        'df': 'Distrito Federal',\n",
    "        'es': 'Espírito Santo',\n",
    "        'go': 'Goiás',\n",
    "        'hm': 'Hemominas',\n",
    "        'ma': 'Maranhão',\n",
    "        'mg': 'Minas Gerais', # Adicionado para teste/exemplo\n",
    "        'rj': 'Rio de Janeiro', # Adicionado para teste/exemplo\n",
    "        # Adicione outros estados/entidades conforme necessário:\n",
    "        # 'sp': 'São Paulo',\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "def extrair_estado_do_nome_arquivo(nome_arquivo):\n",
    "    \"\"\"\n",
    "    Extrai o nome do estado a partir do nome do arquivo, assumindo o formato 'hemoprod_XX_...'.\n",
    "    \n",
    "    IMPORTANTE: Este nome de arquivo DEVE VIR SEM A EXTENSÃO (.xlsx)\n",
    "    \"\"\"\n",
    "    mapeamento = obter_mapeamento_estados()\n",
    "    \n",
    "    # 1. Tenta extrair o código de duas letras após 'hemoprod_'\n",
    "    try:\n",
    "        # Exemplo: 'hemoprod_al_dados' -> 'al_dados'\n",
    "        # Se 'hemoprod_' não estiver presente, pode dar IndexError\n",
    "        parte_codigo = nome_arquivo.split('hemoprod_', 1)[1]\n",
    "        \n",
    "        # Exemplo: 'al_dados' -> 'al'\n",
    "        codigo = parte_codigo.split('_', 1)[0].lower()\n",
    "        \n",
    "        # 2. Busca o código no mapeamento\n",
    "        estado = mapeamento.get(codigo)\n",
    "        \n",
    "        if estado:\n",
    "            return estado\n",
    "        else:\n",
    "            return f'Estado Desconhecido (Código: {codigo})'\n",
    "            \n",
    "    except IndexError:\n",
    "        # Se o formato 'hemoprod_...' não for encontrado\n",
    "        return 'Estado Desconhecido (Formato Inválido)'\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# SCRIPT PRINCIPAL DE PROCESSAMENTO\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# 1. Defina o caminho para os seus arquivos XLSX\n",
    "# Altere 'caminho/para/seus/arquivos' para o diretório onde os arquivos .xlsx estão.\n",
    "path = 'dados_processados' \n",
    "all_files = glob.glob(os.path.join(path, \"*.xlsx\"))\n",
    "\n",
    "# Lista para armazenar os DataFrames de cada arquivo\n",
    "lista_dfs = []\n",
    "\n",
    "# 2. Leia cada arquivo XLSX e adicione à lista\n",
    "print(\"Iniciando a leitura dos arquivos XLSX...\")\n",
    "for filename in all_files:\n",
    "    try:\n",
    "        df = pd.read_excel(filename, sheet_name=0) \n",
    "        \n",
    "        # --- AJUSTE AQUI: Remove a extensão antes de extrair o estado ---\n",
    "        nome_completo = os.path.basename(filename)\n",
    "        # nome_base: 'hemoprod_al_dados' (sem .xlsx)\n",
    "        nome_base, _ = os.path.splitext(nome_completo)\n",
    "        \n",
    "        # Adiciona a coluna com o nome do arquivo de origem (com extensão)\n",
    "        df['origem_arquivo'] = nome_completo\n",
    "        \n",
    "        # NOVO: Adiciona a coluna 'estado' usando a função de extração\n",
    "        # Passa o nome_base SEM a extensão para a função\n",
    "        estado = extrair_estado_do_nome_arquivo(nome_base)\n",
    "        df['estado'] = estado\n",
    "        \n",
    "        lista_dfs.append(df)\n",
    "        print(f\"Arquivo lido com sucesso: {filename}. Estado atribuído: {estado}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao ler o arquivo {filename}: {e}\")\n",
    "        \n",
    "# 3. Concatene todos os DataFrames em um único DataFrame\n",
    "if lista_dfs:\n",
    "    # Concatena todos os DataFrames\n",
    "    df_final = pd.concat(lista_dfs, axis=0, ignore_index=True)\n",
    "    print(\"\\nTodos os arquivos foram concatenados em um único DataFrame.\")\n",
    "    print(f\"Shape do DataFrame final: {df_final.shape}\")\n",
    "\n",
    "    # --- VERIFICAÇÃO DO CAMPO 'estado' (HEAD) ---\n",
    "    print(\"\\n--- Head da Coluna 'estado' para verificação ---\")\n",
    "    print(df_final['estado'].head(10))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # TRATAMENTO DE COLUNAS DE DATA (SOLUÇÃO PARA O ArrowTypeError)\n",
    "    # -------------------------------------------------------------\n",
    "    colunas_datas = ['data_inicio', 'data_ultima_acao']\n",
    "    \n",
    "    for coluna in colunas_datas:\n",
    "        if coluna in df_final.columns:\n",
    "            print(f\"Tentando converter a coluna '{coluna}' para o tipo datetime...\")\n",
    "            df_final[coluna] = pd.to_datetime(df_final[coluna], errors='coerce')\n",
    "            print(f\"Conversão de '{coluna}' concluída. Novo tipo: {df_final[coluna].dtype}\")\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # TRATAMENTO: COLUNAS STRING (SOLUÇÃO PARA TIPOS MISTOS)\n",
    "    # -------------------------------------------------------------\n",
    "    colunas_strings = ['ip', 'cnpj', 'cnes', 'hemoprod_1_observacoes', 'hemoprod_3_observacoes', 'estado'] \n",
    "    \n",
    "    for coluna in colunas_strings:\n",
    "        if coluna in df_final.columns:\n",
    "            print(f\"Tentando converter a coluna '{coluna}' para o tipo string...\")\n",
    "            df_final[coluna] = df_final[coluna].astype(str)\n",
    "            print(f\"Conversão de '{coluna}' concluída. Novo tipo: {df_final[coluna].dtype}\")\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "\n",
    "    # 4. Salve o DataFrame final como um arquivo Parquet\n",
    "    nome_arquivo_parquet = 'dados_processados/hemoprod_nacional.parquet'\n",
    "    \n",
    "    df_final.to_parquet(nome_arquivo_parquet, engine='pyarrow', index=False)\n",
    "    \n",
    "    print(f\"\\nDataFrame salvo com sucesso como '{nome_arquivo_parquet}'\")\n",
    "else:\n",
    "    print(\"\\nNenhum arquivo XLSX foi encontrado ou lido com sucesso. O Parquet não foi criado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
